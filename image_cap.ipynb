{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_cap.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visu27/image-captioning/blob/master/image_cap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K1bdq33gTq4o",
        "colab_type": "code",
        "outputId": "97eb91e9-6186-4e74-a44c-bfcd67c5a570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 22280 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.0-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4MUM1yjrMUkM",
        "colab_type": "code",
        "outputId": "ebbe3b4f-d1c5-44c6-e5a0-0d4ea6d5492b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cRdYE_pYPAZ0",
        "colab_type": "code",
        "outputId": "70bab71b-5596-4051-9c6c-1087aaa5bf29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os,pickle\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import plot_model, to_categorical\n",
        "from keras.layers import Input,Dense\n",
        "from keras.layers import Input, Embedding, Dense, LSTM, Dropout, add,GRU,Reshape,Lambda,BatchNormalization\n",
        "from keras.models import load_model\n",
        "from matplotlib.pyplot import imread, imshow\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from math import ceil\n",
        "from  keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu,sentence_bleu\n",
        "from time import time\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "socafq1vP-sc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_features(directory):\n",
        "\tmodel = VGG16()\n",
        "\tmodel.layers.pop()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "\tfeatures = dict()\n",
        "\tfor name in os.listdir(directory):\n",
        "\t\tfilename = directory + '/' + name\n",
        "\t\timage = load_img(filename, target_size=(224, 224))\n",
        "\t\timage = img_to_array(image)\n",
        "\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t\timage = preprocess_input(image)\n",
        "\t\tfeature = model.predict(image, verbose=0)\n",
        "\t\timage_id = name.split('.')[0]\n",
        "\t\tfeatures[image_id] = feature\n",
        "\treturn features\n",
        "directory = 'drive/img_data/data/Flicker8k_Dataset'\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "pickle.dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGOy1xUiv0Iu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth) \n",
        "file = drive.CreateFile({'title': 'features.pkl'})\n",
        "file.SetContentFile('features.pkl')\n",
        "file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qpTgfRmzOoC",
        "colab_type": "code",
        "outputId": "556961d0-9287-4ea3-87fe-952b9e8e209f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_filename= 'drive/img_data/text/Flickr_8k.trainImages.txt'\n",
        "val_filename= 'drive/img_data/text/Flickr_8k.devImages.txt'\n",
        "image_filename='drive/img_data/features.pkl'\n",
        "def load_descriptions(filename): \n",
        "    map_to_text= {}\n",
        "    data= open(filename,'r').read()\n",
        "    for line in data.split('\\n'):\n",
        "        tokens = line.split()\n",
        "        if(len(tokens)<2):\n",
        "            continue\n",
        "        image_id , image_desc = tokens[0], tokens[1:]\n",
        "        desc = [t.lower() for t in image_desc if(len(t)>1) and t.isalpha()]\n",
        "        image_desc = 'startseq '+' '.join(desc)+' endseq'\n",
        "        image_id= image_id.split('.')[0]\n",
        "        if image_id not in map_to_text:\n",
        "            map_to_text[image_id]=list()\n",
        "        map_to_text[image_id].append(image_desc)\n",
        "    return map_to_text\n",
        "map_to_text= load_descriptions('drive/img_data/text/Flickr8k.token.txt')\n",
        "print(len(map_to_text))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rg8n7ZHHrtNP",
        "colab_type": "code",
        "outputId": "16e2ac8b-64a0-4f3c-8c62-a71d32b6c5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def extract_vocab(map_to_text):\n",
        "    vocab=set()\n",
        "    for key,values in map_to_text.items():\n",
        "        for value in values:\n",
        "            vocab.update(value.split())\n",
        "    return vocab\n",
        "vocab= extract_vocab(map_to_text)        \n",
        "print(len(vocab))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2dsqmJw1tJKi",
        "colab_type": "code",
        "outputId": "ff8c86f5-e37b-49d0-e10f-a3abe27afa54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def load_ids(filename):\n",
        "    data= open(filename,'r')\n",
        "    ids=[]\n",
        "    for image in data.readlines():\n",
        "        ids.append(image.split('.')[0])\n",
        "    return ids\n",
        "def load_descriptions(map_to_text,ids): \n",
        "    data= {}\n",
        "    for key,value in map_to_text.items():\n",
        "        if key in ids:\n",
        "            data[key]=value\n",
        "    return data\n",
        "def load_image_features(filename,ids):\n",
        "    features_dict= pickle.load(open(filename,'rb'))\n",
        "    data={}\n",
        "    for key,value in features_dict.items():\n",
        "        if key in ids:\n",
        "            data[key]=value\n",
        "    return data\n",
        "def  create_tokenizer(descriptions):\n",
        "    data=[]\n",
        "    for key,values in descriptions.items():\n",
        "        [data.append(value) for value in values]\n",
        "    token=Tokenizer()\n",
        "    token.fit_on_texts(data)\n",
        "    return token\n",
        "train_ids = load_ids(train_filename)\n",
        "val_ids = load_ids(val_filename)\n",
        "train_desc = load_descriptions(map_to_text,train_ids)\n",
        "val_desc = load_descriptions(map_to_text,val_ids)\n",
        "train_img= load_image_features(image_filename,train_ids)\n",
        "val_img= load_image_features(image_filename,val_ids)\n",
        "tokenizer= create_tokenizer(train_desc)\n",
        "vocab_size=len(tokenizer.word_index)+1\n",
        "print(vocab_size)\n",
        "def max_length(descriptions):\n",
        "    data=[]\n",
        "    for key,values in descriptions.items():\n",
        "        [data.append(value) for value in values]\n",
        "    return max(len(d.split()) for d in data)\n",
        "max_len = max(max_length(train_desc),max_length(val_desc))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XUPiISszuThz",
        "colab_type": "code",
        "outputId": "479f4681-eaf2-4f2b-ecaf-059ddcbe0f76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def create_sequences(tokenizer, max_length, desc_list, photo):\n",
        "\tX1, X2, y = list(), list(), list()\n",
        "\tfor desc in desc_list:\n",
        "\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t\tfor i in range(1, len(seq)):\n",
        "\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t\tX1.append(photo)\n",
        "\t\t\tX2.append(in_seq)\n",
        "\t\t\ty.append(out_seq)\n",
        "\treturn np.array(X1), np.array(X2), np.array(y)\n",
        "\n",
        "\n",
        "def gen_model(vocab_size, seq_length):\n",
        "    inputs1 = Input(shape=(4096,))\n",
        "    fe1 = Dense(256, activation='relu')(inputs1)\n",
        "    fe2 = Dropout(0.5)(fe1)\n",
        "    inputs2 = Input(shape=(seq_length,))\n",
        "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "    se2 = Dropout(0.5)(se1)\n",
        "    se3 = LSTM(256)(se2)\n",
        "    decoder1 = add([fe2, se3])\n",
        "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    return model\n",
        "def data_generator(descriptions, photos, tokenizer, max_length):\n",
        "    while 1:\n",
        "      for key, desc_list in descriptions.items():\n",
        "        photo = photos[key][0]\n",
        "        in_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo)\n",
        "        yield [[in_img, in_seq], out_word]\n",
        "model=gen_model(vocab_size,max_len)\n",
        "filepath = 'drive/img_data/final_lstmimagecaption3layers_img_hidd-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, mode='min')\n",
        "epochs = 20\n",
        "steps = len(train_desc)\n",
        "val_steps = len(val_desc)\n",
        "for i in range(epochs):\n",
        "    generator = data_generator(train_desc, train_img, tokenizer, max_len)\n",
        "    val_generator= data_generator(val_desc,val_img,tokenizer,max_len)\n",
        "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps,callbacks=[checkpoint], verbose=1,validation_data=val_generator, validation_steps=val_steps)\n",
        "    print(str(i+1 )+' epochs Finished'+' out of '+ str(epochs) )\n",
        "    model.save('model_' + str(i) + '.h5')\n",
        "model.save('drive/img_data/final_lstm3_imglstm_img_hidd_final.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 701s 117ms/step - loss: 4.7360 - val_loss: 4.2467\n",
            "1 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 702s 117ms/step - loss: 4.0312 - val_loss: 4.0325\n",
            "2 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 700s 117ms/step - loss: 3.7862 - val_loss: 3.9740\n",
            "3 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 698s 116ms/step - loss: 3.6367 - val_loss: 3.9540\n",
            "4 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 695s 116ms/step - loss: 3.5378 - val_loss: 3.9426\n",
            "5 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 698s 116ms/step - loss: 3.4661 - val_loss: 3.9407\n",
            "6 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 698s 116ms/step - loss: 3.4077 - val_loss: 3.9575\n",
            "7 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 695s 116ms/step - loss: 3.3612 - val_loss: 3.9739\n",
            "8 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 698s 116ms/step - loss: 3.3213 - val_loss: 3.9862\n",
            "9 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 696s 116ms/step - loss: 3.2878 - val_loss: 4.0087\n",
            "10 epochs Finished out of 20\n",
            "Epoch 1/1\n",
            "2021/6000 [=========>....................] - ETA: 7:23 - loss: 3.2236Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2T_vCeTogc6T",
        "colab_type": "code",
        "outputId": "4ede91b7-1216-4dc4-9af3-a6bb13a54f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "  in_text = 'startseq'\n",
        "  for i in range(max_length):\n",
        "    sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "    sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "    yhat = model.predict([photo,sequence], verbose=0)\n",
        "    yhat = np.argmax(yhat)\n",
        "    word = word_for_id(yhat, tokenizer)\n",
        "    if word is None:\n",
        "      break\n",
        "    in_text += ' ' + word\n",
        "    if word == 'endseq':\n",
        "      break\n",
        "  return in_text\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "  actual, predicted = list(), list()\n",
        "  for key, desc_list in descriptions.items():\n",
        "    yhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "    references = [d.split() for d in desc_list]\n",
        "    actual.append(references)\n",
        "    predicted.append(yhat.split())\n",
        "  print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "  print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "  print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "  print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "f1='drive/img_data/final_lstm3_imglstm_img_hidd_final2.h5'\n",
        "model = load_model(f1)\n",
        "evaluate_model(model, val_desc, val_img, tokenizer, max_len)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.477018\n",
            "BLEU-2: 0.241297\n",
            "BLEU-3: 0.161354\n",
            "BLEU-4: 0.069397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yxAW5MV9T7dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8efb015a-85c9-4ac9-89ff-f64c80acb8d7"
      },
      "cell_type": "code",
      "source": [
        "index_word= dict(map(reversed, tokenizer.word_index.items()))\n",
        "def beam_search_predict_captions(img,tokenizer,max_len=33,beam_width=3):\n",
        "    start= 'startseq'\n",
        "    count_tokens=0\n",
        "    token_input= np.zeros((1,33))\n",
        "    z= np.zeros((1,512))\n",
        "    token_input[0,count_tokens]= 1\n",
        "    beam_outputs=[[token_input,-10.0]]\n",
        "    while count_tokens<max_len-1 : \n",
        "      tmp=[]\n",
        "      for i in beam_outputs:\n",
        "        x,score = i\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        #x= np.reshape(1,1,33)\n",
        "        #x1 = pad_sequences([x],max_len,padding='post')[0]\n",
        "        outputs = model.predict([np.array(img),np.array(x),z])\n",
        "        out = np.array(outputs[count_tokens][0].ravel())\n",
        "        top_beam = np.argsort(out)[-beam_width:]\n",
        "        #print(top_beam)\n",
        "        for p in top_beam:\n",
        "          #print(p)\n",
        "          x1=np.copy(x)\n",
        "          x1[0,count_tokens+1]= p\n",
        "          #print(x1)\n",
        "          new_score= ((count_tokens*score+ np.log(out[p])))/(count_tokens+1)\n",
        "          #new_score= score+ np.log(out[p])\n",
        "          #print(new_score)\n",
        "          tmp.append([x1,new_score])\n",
        "          #print(tmp)\n",
        "      #print(tmp)\n",
        "      #beam_outputs.extend(tmp)\n",
        "      #print(len(beam_outputs))\n",
        "      beam_outputs=tmp\n",
        "      beam_outputs=sorted(beam_outputs,key= lambda x : x[1],reverse=True)\n",
        "      beam_outputs = beam_outputs[0:beam_width]\n",
        "      #print((beam_outputs))\n",
        "      count_tokens = count_tokens+1\n",
        "    beam_outputs=sorted(beam_outputs,key= lambda x : x[1],reverse=True)\n",
        "    ans= beam_outputs[0][0].ravel()\n",
        "    #print(ans)\n",
        "    sentence=[]\n",
        "    for out in ans:\n",
        "        string= index_word[out]\n",
        "        sentence+= [string]\n",
        "        if string=='endseq':\n",
        "            break\n",
        "    return sentence\n",
        "def evaluate_model(model ,descriptions, features, tokenizer,beam_width):\n",
        "    actual, predicted = list(), list()\n",
        "    samples = len(descriptions.items())\n",
        "    for key, desc_list in descriptions.items():\n",
        "        prediction = beam_search_predict_captions(features[key],tokenizer,beam_width=beam_width)\n",
        "        references = [d.split() for d in desc_list]\n",
        "        actual.append(references)\n",
        "        predicted.append(prediction)\n",
        "        #print(prediction)\n",
        "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "f='drive/img_data/final_lstm3_imglstm_img_hidd_final.h5'\n",
        "model = load_model(f)\n",
        "evaluate_model(model, val_desc, val_img, tokenizer, 3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.415955\n",
            "BLEU-2: 0.192152\n",
            "BLEU-3: 0.095778\n",
            "BLEU-4: 0.023780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gok6aFdOTbAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1aec14a0-27cf-4290-a99a-7e81b6411375"
      },
      "cell_type": "code",
      "source": [
        "def extract_features(filename):\n",
        "\tmodel = VGG16()\n",
        "\tmodel.layers.pop()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "\timage = load_img(filename, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\timage = preprocess_input(image)\n",
        "\tfeature = model.predict(image, verbose=0)\n",
        "\treturn feature\n",
        "\n",
        "photo = extract_features('drive/download.jpg')\n",
        "#desc=beam_search_predict_captions(photo,tokenizer,3)\n",
        "desc=generate_desc(model, tokenizer, photo, max_len)\n",
        "print(desc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "startseq dog is running through the grass with its tongue hanging out endseq\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}